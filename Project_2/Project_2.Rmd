---
title: 'Compulsory exercise 2: Group 12'
author: "Emma Skarnes, Håkon Noren  and Alexander Johan Arntzen"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document: default
  html_document:
    df_print: paged
subtitle: TMA4268 Statistical Learning V2020
---
  
```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(eval = TRUE, echo = TRUE,tidy=TRUE,message=FALSE,warning=FALSE,strip.white=TRUE,prompt=FALSE,
                      cache=TRUE, size="scriptsize",fig.width=4, fig.height=3)

```

```{r,eval=TRUE,echo=FALSE}
#install.packages("knitr") #probably already installed
#install.packages("rmarkdown") #probably already installed
#install.packages("ggplot2") #plotting with ggplot
#install.packages("ISLR")
#install.packages("MASS")
#install.packages("GGally")
#install.packages("glmnet")
#install.packages("e1071")
#install.packages("tree")
#install.packages("leaps")
#install.packages("randomForest")
#install.packages("gbm")
#install.packages("ggfortify")

library(knitr)
library(rmarkdown)
library(GGally)
library(ggplot2)
library(ggfortify)
library(MASS)
library(ISLR)
library(dplyr)
library(boot)
library(Rfast)
library(formatR)
library(e1071)
library(corrplot)
library(tree)
theme_set(theme_bw())
```

# Problem 1

## a)

## b)

## c)

## d)

## e)



# Problem 2

## a)

## b)

## c)

## d)



# Problem 3

## a)

## b)

## c)



# Problem 4
In this problem we use the data set of diabetes from a population of women of Pima Indian heritage in the US. We split the data set into a training set of 300 observations, where 200 are non-diabetic and 100 are diabetic, and a test with of 232 observations, where 155 are non-diabetic and 77 are diabetic. 

``` {r, eval = TRUE, echo = FALSE}
id <- "1Fv6xwKLSZHldRAC1MrcK2mzdOYnbgv0E" # google file ID
d.diabetes <- dget(sprintf("https://docs.google.com/uc?id=%s&export=download",
                           id))
d.train = d.diabetes$ctrain
d.test = d.diabetes$ctest
```

## a)
To get to know the data, it is useful to produce some summaries and plots (NB! Fjern denne teksten før innlevering!!)
```{r, eval = TRUE, echo = TRUE}
# DENNE FJERNES FØR INNLEVERING, LAR DEN STÅ ENN SÅ LENGE SÅ DEN SOM SKAL SE OVER HAR NOE Å TA UTGANGSPUNKT I
summary(d.train)
cor(d.train)
corrplot(cor(d.train))
ggpairs(d.train)
```
TRUE, TRUE, TRUE, TRUE (???)

## b)
To fit a support vector classifier and a support vector machine to the problem, the response variable $\texttt{diabetes}$ must first be converted into a factor variable.
```{r, eval = TRUE, echo = FALSE} 
d.train$diabetes = as.factor(d.train$diabetes)
d.test$diabetes = as.factor(d.test$diabetes)
```
We start by fitting a support vector classifier, which has a linear boundary. To find a good cost parameter, cross-validation is used. The confusion table and the misclassification error reported are for the test set.

```{r, eval = TRUE, echo = TRUE}
svc = svm(diabetes ~ ., data = d.train, kernel = "linear", cost = 0.1, scale = FALSE)

# Find best cost for SVC
set.seed(1)
tune.cost = tune(method = "svm", diabetes ~ ., data = d.train, kernel = "linear", 
                ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
summary(tune.cost)                 # 0.1 is the best cost
svc.bestmod = tune.cost$best.model

svc.pred = predict(svc.bestmod, d.test)
svc.ct = table(predict = svc.pred, truth = d.test$diabetes)  # Confusion table
svc.mcr = 1 - sum(diag(svc.ct))/sum(svc.ct)                  # Misclassification error rate
print(paste0("Confusion table: ", svc.ct))
print(paste0("Misclassification error rate: ", svc.mcr))
```

Similarly, we now fit a support vector machine with a radial boundary. Cross-validation is now used to find the optimal combination of cost and $\gamma$ parameters. 
```{r, eval = TRUE, echo = TRUE}
svmfit = svm(diabetes ~., data = d.train, kernel = "radial", gamma = 0.5, cost = 1, scale = FALSE)

# Find the best cost and gamma for SVM
set.seed(1)
tune.costgamma = tune(method = "svm", diabetes ~ ., data = d.train, kernel = "radial", 
                ranges = list(cost = c(0.1, 1, 5, 10, 100), 
                              gamma = c(0.5, 1, 2, 3, 4)))
summary(tune.costgamma)
svm.bestmod = tune.costgamma$best.model

svm.pred = predict(svm.bestmod, d.test)
svm.ct = table(predict = svm.pred, truth = d.test$diabetes)
svm.mcr = 1 - sum(diag(svm.ct))/sum(svm.ct)
print(paste0("Confusion table: ", svm.ct))
print(paste0("Misclassification error rate: ", svm.mcr))
```
Based on the confusion tables and their associated misclassification error rates, we can see that the support vector classifier performs better than the support vector machine, with a misclassification error rate of $0.228$ instead of $0.259$ for the support vector machine. Out of these two classifiers, we thus prefer the support vector classifier, even if the difference is relatively small.  

## c)
We now compare the performance of the two classifiers from 4b) to a classification tree. As for the SVC and SVM we fit a model, now a classification tree, to our training set, before we use the test set to find the confusion table and misclassification error rate of the method.
```{r, eval = TRUE, echo = TRUE}
d.tree = tree(diabetes ~ ., data = d.train)
tree.pred = predict(d.tree, d.test$diabetes, type = "class")
tree.ct = table(tree.pred, d.test$diabetes)
tree.mcr = 1 - sum(diag(tree.ct))/sum(tree.ct)
print(paste0("Confusion table: ", tree.ct))
print(paste0("Misclassification error rate: ", tree.mcr))
```

```{r, eval = TRUE, echo = FALSE}
# Does pruning the tree improve the results?
set.seed(2)
d.cv = cv.tree(d.tree, FUN = prune.misclass)
d.cv

d.prune = prune.misclass(d.tree, best = )
tree.predict = predict(d.prune, d.test, type = "class")
tree.conft = table(tree.predict, d.test$diabetes)
tree.misclassr = 1 - sum(diag(tree.conft))/sum(tree.conft)
tree.conft
tree.misclassr    # No, it does not improve the results

# DENNE DELEN KAN OGSÅ FJERNES FØR INNLEVERING, KUN HER FOR AT DEN SOM SER OVER SKAL SLIPPE Å SKRIVE KODE FOR Å SJEKKE OM PRUNING FORBEDRER METODEN
```
To check that the performance of our classification tree was optimal, the tree was pruned. The pruning did not improve the result, and was thus rejected. We observe from the confusion table and the misclassification error rate that the classification tree performed better than the support vector machine, but worse than the support vector classifier. 

Advantages/disadvantages of classification trees wrt. SVMs

## d)
Multiple choice

## e)
Link to logistic regression and hinge loss


# Problem 5

## a)

## b)

## c)

## d)

## e)

## f)