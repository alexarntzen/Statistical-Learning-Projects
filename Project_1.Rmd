---
subtitle: "TMA4268 Statistical Learning V2019"
title: "Compulsory exercise 1: Group 12"
author: "Emma Skarnes, HÃ¥kon Noren  and Alexander Johan Arntzen"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  # html_document
  pdf_document
---
  
```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE,tidy=TRUE,message=FALSE,warning=FALSE,strip.white=TRUE,prompt=FALSE,
                      cache=TRUE, size="scriptsize",fig.width=4, fig.height=3)

```

```{r,eval=TRUE,echo=FALSE}
# install.packages("knitr") #probably already installed
# install.packages("rmarkdown") #probably already installed
# install.packages("ggplot2") #plotting with ggplot
# install.packages("ggfortify")  
# install.packages("MASS")  
# install.packages("dplyr")  
library(knitr)
library(rmarkdown)
library(ggplot2)
library(ggfortify)
library(MASS)
library(dplyr)
library(boot)
library(Rfast)
theme_set(theme_bw())

```


# Problem 1

For this problem you will need to include some LaTex code. Please install latex on your computer and then consult Compulsor1.Rmd for hints how to write formulas in LaTex.

## a)
The expected test mean squared error (MSE) at "x_{0}" is 
$$
 E[y_{0} -\hat{f}(x_{0}) ]^{2}.
 \eqref{eq:1}
$$

Where $y_{0}$ is the new observation.
## b)

Firstly we from computation it is clear that 
$$
\begin{align}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\E}{\mathrm{E}}
\E[ f( x_{0}) -\hat{f}( x_{0})]^{2} & =\E[ f( x_{0}) -\E[\hat{f}( x_{0})] +\E[\hat{f}( x_{0})] -\hat{f}( x_{0})]^{2}\\
 & =\E[ f( x_{0}) -\E[\hat{f}( x_{0})]]^{2} +2\E[ f( x_{0}) -\E[\hat{f}( x_{0})] \ ][ \E[\hat{f}( x_{0})] -\hat{f}( x_{0})] +\E[ \E[\hat{f}( x_{0})] -\hat{f}( x_{0})]^{2}\\
 & =( f( x_{0}) -\E[\hat{f}( x_{0})])^{2} \  + \Var[ f( x_{0})].
\end{align}
$$
Secondly note that $y_0$ and the training data are independent. In addition $\mathrm{E}[ \epsilon ] \ =\ 0 $ Then expanding equation $\ref{eq:1.1}$ and using equation $\ref{eq:1.2}$ the decomposition becomes 

$$
\begin{align}
\E[ y_{0} -\hat{f}( x_{0})]^{2} & \ =\E[ f( x_{0}) +\epsilon -\hat{f}( x_{0})]^{2}\\
 & =\E[ \epsilon - \E[ \epsilon ]]^{2} +2\E[ \epsilon ] \E[ f( x_{0}) -\hat{f}( x_{0})] +\E[ f( x_{0}) -\hat{f}( x_{0})]^{2} \ \\
 & =\Var[ \epsilon ] + [ f( x_{0}) - \E[\hat{f}( x_{0})]]^{2}   + \Var[ f( x_{0})].
\end{align}
$$
## c)
Since variance and squared expression cannot be negative each of the three terms contributes to the expected test MSE at $x_0$. The

$\pmb{\Var[ \epsilon ]}$ is the **irreducible error**. It is independent of the model and cannot be reduced. 


$\pmb{\Var[ f( x_{0})]}$ is the **variance** of the prediction at $x_{0}. It is a measure of how much the model will change based on different training data. In general the variance of the model decreases with the flexibility of the model. x

$[ f( x_{0}) - \E[\hat{f}( x_{0})]]^{2}$ is the **squared bias** at $x_{0}$, also denoted $\mathrm{Bias}(\hat{f}( x_{0}))]^{2}$. It is a measure of much the model differs from the target function $f$ at $x_{0}$. In general a flexible model will have low bias. For example


A good model will strike a balance between bias and variance to achieve a low total expected test MSE. 
## d)
TRUE, FALSE, FALSE, TRUE
% Litt usikker her noen burde sjekke. 
## e)
TRUE, FALSE, TRUE, FALSE. 

## f)
(ii)
## g)
C

# Problem 2

Here is a code chunk:

```{r, eval=TRUE}
#id <- "1nLen1ckdnX4P9n8ShZeU7zbXpLc7qiwt" # google file ID
#d.worm <- read.csv(sprintf("https://docs.google.com/uc?id=%s&export=download", id))
#head(d.worm)
```


## a)
The dataset consists of 143 rows and 5 columns. This can for example be seen from running the function str(d.worm).
The qualitative variables are Gattung, FANGDATUM and Nummer, while the quantitative variables are GEWICHT and MAGENUMF.
SJEKK DETTE !!!


## b) 
```{r, eval=TRUE, echo=TRUE, fig.width=8, fig.height=6}
# Change figure dimensions? Standard width 4 and height 3
ggplot(d.worm, aes(x = GEWICHT, y = MAGENUMF, colour = Gattung)) + geom_point() + theme_bw()

# Transform to get a linear relationship
ggplot(d.worm, aes(x = log(GEWICHT), y = log(MAGENUMF), colour = Gattung)) + geom_point() + theme_bw()
```
The relationship in the original scatterplot does not look linear, so we linearize it by transforming the quantitative variables. 


## c)
```{r, eval=TRUE, echo=TRUE}
fit.lm = lm(log(GEWICHT) ~ log(MAGENUMF) + Gattung, data = d.worm) # Fitting a reg. model
summary(fit.lm)
anova(fit.lm)

# Separate reg. models and equations
```

We can see that Gattung seems to be a relevant predictor since the p-values for the different species are high, and so is the F-statistic. This implies ...

## d)
```{r, eval=TRUE, echo=TRUE}
# Test interaction term
fit.lmInter = lm(log(GEWICHT) ~ log(MAGENUMF) * Gattung, data = d.worm)
summary(fit.lmInter)
anova(fit.lmInter)
```
Comment on whether the interaction term is relevant or not ++

## e)
```{r,eval=TRUE, echo=TRUE}
autoplot(fit.lm)   # Residual analysis on our regression model

# Compare to the model without transformed variables 
fit.lm1 = lm(GEWICHT ~ MAGENUMF + Gattung, data = d.worm)
autoplot(fit.lm1, smooth.colour = NA)
```
The Residuals vs. fitted plot, or Tukey-Anscombe, seems to be nonlinear, which is how we want the residuals to behave. 
We have some outliers in the QQ-plot, especially points 7, 96 and 2. However, the majority of the points are making up a fairly straight line, so some outliers does not imply that our assumptions are violated. 
In the Scale-Location plot, the points seems to gather a little bit as the x-value, fitted values, increases. This can be a sign of non-equal variances, which is violating our assumptions. 
The Constant Leverage: Residuals vs Factor Levels plot, we can see that the spread of the points seems to differ based on the species. While there is only one outlier for the Lumbricus species, there are more outliers for the two other species, even though these are not as far from the majority as the outlier in L.
<b> ??? </b>


## f)

## g)


# Problem 3

## a)

## b)

## c)

## d)

## e)

## f)

## g)

## h)


# Problem 4
## a)
10 fold cross validation on the KNN regression would be performed by partitioning the training data $D$ into 10 equal size sets $D_i$. For each of the 10 sets, leave the set out form the data and calculate a test error using the set as test data. Then average the test errors for all the 10 sets. More precisely we would use test MSE as error measure. let $\mathcal{N_i(x)}$ be the $K$ closest point in $D \setminus	D_i$ to $x$. The test MSE is calculated as 
$$
\mathrm{MSE}_{i}=\frac{1}{|D_i|}\sum^{|D_i|}_{j=1}{(y_j-\frac{1}{K}\sum_{l\in \mathcal{N_i(x_j)}}{y_l} )^2 },
$$
where $y_j,y_j \in D_i$ and $y_l$ is the observed response at $l$. The validation error is then calculated as 

$$
\mathrm{CV}_{10}=\frac{1}{10}\sum^{10}_{i=10}{\mathrm{MSE}_{i}}.
$$

## b)
TRUE, TRUE, TRUE, FALSE 

## c)
```{r, eval=FALSE, echo=TRUE}

 id <- "1I6dk1fA4ujBjZPo3Xj8pIfnzIa94WKcy" # google file ID
d_chd <- read.csv(sprintf("https://docs.google.com/uc?id=%s&export=download",
id))


get_f_hat <- function(chd_data){
  logitRegChd <- glm(chd~sbp+sex, data=chd_data, family="binomial")
  b <- coef(logitRegChd)[1]
  bSpb <- coef(logitRegChd)[2]
  bSex <- coef(logitRegChd)[3]
  return(function(spb,sex) {
    return (exp(b+bSpb*spb + bSex*sex)/(1+exp(b+bSpb*spb + bSex*sex)))
  })
  
 }
f_hat <- get_f_hat(d_chd)

chdProbability <- unname(f_hat(140,1))

testPlotFemale <- ggplot(subset(d_chd, sex == 0), aes(x=subset(sbp, sex == 0), y=subset(chd, sex == 0)))+geom_point() + geom_line(aes(x=sbp, y=f_hat(sbp,1)), col="blue")

testPlotMale <- ggplot(subset(d_chd, sex == 1), aes(x=subset(sbp, sex == 1), y=subset(chd, sex == 1)))+geom_point() + geom_line(aes(x=sbp, y=f_hat(sbp,2)), col="blue")

testPlotFemale

testPlotMale 
```
"The probability of chd for a male with a sbp=140 is `r chdProbability`.


## d)

```{r, eval=FALSE, echo=TRUE}

library(dplyr)
library(boot)

eval_f_hat <- function(sbp,sex){
  return(
    function(data,indexs) {
      get_f_hat(data[indexs,])(sbp,sex)
    }
  )
}


boostrap_stats <- function(data,stat_func, num_samples ){
  rows <- nrow(data)
  boostrap_stats <- numeric(num_samples)
  for (b in 1:num_samples){
    indexs = sample.int(n =rows,size = rows,replace= TRUE)
    boostrap_stats[b] <- stat_func(data,indexs) 
  }
  return(boostrap_stats)
} 
probs <- boostrap_stats(d_chd,eval_f_hat(140,1),1000)
bootProbs<-  boot(data = d_chd,statistic = eval_f_hat(140,1) , R = 1000)
stdError = sd(probs)
ggplot(data = data.frame(x=bootProbs$t),aes(x=x))+   geom_density() + geom_density(data = data.frame(x=probs),aes(x=x), color = "red")

#Confidence interval

#Removing top 1000*(1-a/2) from each end 

low = Rfast::nth(probs, 26, descending = FALSE)
high = Rfast::nth(probs, 26, descending = TRUE)


```
from the probabilies we get a standard error of `r stdError`.A $95\%$ confidence interval for the the estimator of $P(\mathrm{chd} | \mathrm{sex= male},\mathrm{sbp=40})$ is [ `r low` ,`r high`]. 
If we assume the estimated distribution to be true it means that the estimator will take values in [ `r low` ,`r high`]  $95\%$ of the time. This indicates that the estimator has a high variance, but we don't know if it has low or high bias. 




